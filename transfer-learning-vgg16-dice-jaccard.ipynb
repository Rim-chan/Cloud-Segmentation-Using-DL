{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport torch\nimport time\nimport os\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nfrom skimage.transform import resize\nimport helper\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nfrom torchvision import datasets\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim, Tensor\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport random\nseed=42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/95cloud-cloud-segmentation-on-satellite-images/95-cloud_training_only_additional_to38-cloud')\nred_dir   = base_path/'train_red_additional_to38cloud'\nblue_dir  = base_path/'train_blue_additional_to38cloud'\ngreen_dir = base_path/'train_green_additional_to38cloud'\nnir_dir   = base_path/'train_nir_additional_to38cloud'\ngt_dir    = base_path/'train_gt_additional_to38cloud'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def OpenAsArray(self, idx, invert=False):\n        \n        raw_rgb=np.stack([np.array(Image.open(self.files[idx]['red'])),\n                          np.array(Image.open(self.files[idx]['green'])),\n                          np.array(Image.open(self.files[idx]['blue']))], axis = 2)\n     \n        \n        if self.transform:\n            raw_rgb= self.transform(Image.fromarray(raw_rgb.astype(np.uint8), 'RGB'))\n             \n    \n        if invert:\n            raw_rgb = np.array(raw_rgb, dtype=np.uint16).transpose((2, 0, 1))\n    \n    \n        return (raw_rgb / np.finfo(raw_rgb).max)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RGB_CloudDataset (Dataset):\n    def __init__(self, red_dir, blue_dir, green_dir, gt_dir, transform= None):\n        \n        \n        self.transform   = transform\n    \n        \n        # Listing subdirectories\n        # Loop through the files in red folder  \n        # and combine, into a dictionary, the other bands\n        \n        self.files = [self.combine_files(f, green_dir, blue_dir, gt_dir) \n                      for f in red_dir.iterdir() if not f.is_dir()]\n        \n        random.seed (seed)\n        self.files = random.sample (self.files, k= 2000)\n        \n        \n    def combine_files(self, red_file: Path, green_dir, blue_dir, gt_dir):\n        \n        files = {'red': red_file, \n                 'green':green_dir/red_file.name.replace('red', 'green'),\n                 'blue': blue_dir/red_file.name.replace('red', 'blue'), \n                 'gt': gt_dir/red_file.name.replace('red', 'gt')}\n\n        return files\n    \n\n    \n    \n    def OpenAsArray(self, idx, invert=False):\n        \n        TrueColor = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                              np.array(Image.open(self.files[idx]['green'])),\n                              np.array(Image.open(self.files[idx]['blue']))], axis = 2)\n     \n    \n        if invert:\n            TrueColor = TrueColor.transpose((2, 0, 1))\n            \n        \n        return TrueColor\n    \n    \n    \n    def OpenMask(self, idx, add_dims=False):\n        raw_mask=np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n\n\n        \n    def __len__(self):\n        return len(self.files)\n    \n    \n    def __getitem__(self, idx):\n        x = self.OpenAsArray(idx, invert=True)\n        y = self.OpenMask(idx, add_dims=False)\n        \n        \n        if self.transform is not None:\n            x, y = self.transform((x, y))\n        \n        \n        return torch.from_numpy(x), torch.from_numpy(y)\n    \n    \n    def open_as_pil(self, idx):\n        arr = self.OpenAsArray(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')  \n    \n    \n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NirGB_CloudDataset (Dataset):\n    def __init__(self, red_dir, blue_dir, green_dir, nir_dir, gt_dir, transform = None):\n        \n        \n        self.transform = transform\n        \n        # Listing subdirectories\n        # Loop through the files in red folder  \n        # and combine, into a dictionary, the other bands\n        \n        self.files = [self.combine_files(f, green_dir, blue_dir, nir_dir, gt_dir) \n                      for f in red_dir.iterdir() if not f.is_dir()]\n        \n        \n        \n    def combine_files(self, red_file: Path, green_dir, blue_dir, nir_dir, gt_dir):\n        \n        files = {'red': red_file, \n                 'green':green_dir/red_file.name.replace('red', 'green'),\n                 'blue': blue_dir/red_file.name.replace('red', 'blue'), \n                 'nir': nir_dir/red_file.name.replace('red', 'nir'),\n                 'gt': gt_dir/red_file.name.replace('red', 'gt')}\n\n        return files\n    \n    \n    \n    def OpenAsArray(self, idx):\n        \n        FalseColor = np.stack([np.array(Image.open(self.files[idx]['nir'])),\n                               np.array(Image.open(self.files[idx]['green'])),\n                               np.array(Image.open(self.files[idx]['blue']))], axis = 2)\n     \n                    \n        FalseColor      = FalseColor.transpose((2, 0, 1))\n    \n        return (FalseColor / np.iinfo(FalseColor.dtype).max)\n    \n    \n    \n    def OpenMask(self, idx, add_dims=False):\n        raw_mask=np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n\n\n        \n    def __len__(self):\n        return len(self.files)\n    \n    \n    def __getitem__(self, idx):\n        x = self.OpenAsArray(idx)\n        y = self.OpenMask(idx, add_dims=False)\n        return torch.from_numpy(x), torch.from_numpy(y)\n    \n    \n    def open_as_pil(self, idx):\n        arr = 256 * self.OpenAsArray(idx)\n        return Image.fromarray(arr.astype(np.uint8), 'NirGB')  \n    \n    \n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n        return s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Resize(object):\n    def __init__(self, size = 256):\n        self.size = size\n    def __call__(self, sample):\n        x, y = sample\n        return (resize(x, (x.shape[0], self.size, self.size), mode = \"constant\", \n                      preserve_range = True, anti_aliasing = False),\n                resize(y, (self.size, self.size), mode = \"constant\", \n                      preserve_range = True, anti_aliasing = False))\n    \n\nclass Normalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std  = std\n        \n    def __call__(self, sample):\n        x,y =sample\n        x = x.transpose(1,2,0)\n        x=(x-self.mean)/self.std\n        return x.transpose(2,0,1), y\n    \n    \n# Define transforms for the training data and testing data\ntrain_transforms=transforms.Compose([Resize(256),\n                                     Normalize([0.485, 0.456, 0.406], [0.229, 0.224,0.225])])\n\n                       \ntest_transforms=transforms.Compose(Normalize([0.485, 0.456, 0.406], [0.229, 0.224,0.225]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RGB_data   = RGB_CloudDataset(red_dir, blue_dir, green_dir, gt_dir, transform = train_transforms) \nNirGB_data = NirGB_CloudDataset(red_dir, blue_dir, green_dir, nir_dir, gt_dir, transform = None)\n\n# splitting the data into train, validation, and test datasets\n\nRGBtrain_size = int(0.75 * len(RGB_data))\nRGBvalid_size = int(0.15 * len(RGB_data))\nRGBtest_size  = len(RGB_data) - RGBtrain_size - RGBvalid_size\nRGBremaining_size = len(RGB_data) - RGBtrain_size \n\nRGBtrain_dataset, RGBremaining_dataset = torch.utils.data.random_split(RGB_data, \n                                                                       [RGBtrain_size, RGBremaining_size])\nRGBvalid_dataset, RGBtest_dataset      = torch.utils.data.random_split(RGBremaining_dataset, \n                                                                       [RGBvalid_size, RGBtest_size])\n\n\nprint('\\t\\t\\tDataset')\nprint(\"Train data: \\t\\t{}\".format(len(RGBtrain_dataset)),\n      \"\\nValidation data: \\t{}\".format(len(RGBvalid_dataset)),\n     \"\\nTest data: \\t\\t{}\".format(len(RGBtest_dataset)))\n\n\n\nRGBtrain_loader = DataLoader(RGBtrain_dataset, batch_size=12, shuffle=True, num_workers=2)\nRGBvalid_loader = DataLoader(RGBvalid_dataset, batch_size=12, shuffle=True, num_workers=2)\nRGBtest_loader  = DataLoader(RGBtest_dataset , batch_size=12, shuffle=True, num_workers=2)\n\nRGBdata_iter = iter(RGBvalid_loader)\nrgb_img, mask = next(RGBdata_iter)\n\nprint('\\n')\nprint('Raw RGB image shape on batch size = {}'.format(rgb_img.size()))\nprint('Cloud Mask shape on batch size    = {}'.format(mask.size()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (10,9))\n\nax[0].imshow((RGB_data.OpenAsArray(5)))\nax[1].imshow(RGB_data.OpenMask(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model: Pretrained Vgg16**","metadata":{}},{"cell_type":"code","source":"class Vgg16(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        network = models.vgg16(pretrained=True)\n        # Replace the classifier\n        self.modified_network = nn.Sequential(*list((*list(network.children())[:-2],\n                                                     nn.Conv2d(512,2, kernel_size = 1),\n                                                     nn.Upsample(size=(256,256), mode='bilinear', align_corners=False)))) \n    \n    \n    \n    def forward(self, xb):\n        return self.modified_network(xb)\n    \n    def freeze(self):\n        # To freeze the CONV layers\n        for param in self.modified_network[0].parameters():\n            param.require_grad = False\n        for param in self.modified_network[1:].parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.modified_network.parameters():\n            param.require_grad = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Vgg16().to(device)\nmodel.modified_network [0], model.modified_network [1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\n\nclass Evaluation_Metrics(nn.Module):\n    def __init__(self):\n        super(Evaluation_Metrics, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        pred = torch.round(prediction.softmax(dim=1)[:, 1])\n\n        # true positives, false positives, true negatives, false negatives\n        TP = torch.sum(pred * gt)\n        FP = torch.sum(pred * (1-gt))\n        TN = torch.sum((1-pred) * (1-gt))\n        FN = torch.sum((1-pred) * gt)\n    \n    \n        # Dice_Score/F1_Score\n        Dice_Score = (2 * TP + smooth)/(2*TP + FP + FN  + smooth)\n    \n        # Jaccard Coefficient: Intersection over Union\n        IoU = (TP + smooth)/(TP + FP + FN + smooth)\n    \n        # Recall\n        Recall= (TP + smooth)/(TP + FN + smooth)\n    \n        # Precision\n        Precision = (TP + smooth)/(TP + FP + smooth)\n\n    \n        return {'Dice_Score/F1_Score':Dice_Score, 'IoU':IoU, 'Recall': Recall, 'Precision': Precision}\n\n\n# Dice Loss function\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        # Softmax to get probabilities beteen 0 and 1\n        # Transform the prediction tensor of shape (N, C, H, W) --> tensor of shape (N, H, W)\n        pred = prediction.softmax(dim=1)[:, 1]\n        Dice =  (2 * torch.sum(pred * gt)+ smooth)/(torch.sum(pred + gt)+ smooth)\n\n        \n        return 1 - Dice\n\n    \n# Set the evaluation metrics and the loss function\nEvaluation = Evaluation_Metrics()\nloss_fn = DiceLoss()\n\n# Set the optimizer \noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_DSC(train_DSC, valid_DSC):\n    plt.plot(train_DSC, '-bx')\n    plt.plot(valid_DSC, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Dice Coefficient vs. No. of epochs');\n    \ndef plot_losses(train_losses, valid_losses):\n    plt.plot(train_losses, '-bx')\n    plt.plot(valid_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Dice Loss vs. No. of epochs');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze()\nPretrained_Vgg16 = './Pretrained_Vgg16_CloudSegModel.pt'\ntrain_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC = train(model,RGBtrain_loader, RGBvalid_loader, loss_fn, optimizer, Evaluation, epochs=4, save_path = Pretrained_Vgg16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}