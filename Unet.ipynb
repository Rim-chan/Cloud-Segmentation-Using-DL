{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport torch\nimport time\nimport os\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nfrom skimage.transform import resize\nimport helper\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nfrom torchvision import datasets\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim, Tensor\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport random\nseed=42\ntorch.manual_seed(14)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CloudDataset (Dataset):\n    def __init__(self, red_dir, blue_dir, green_dir, nir_dir, gt_dir):\n        \n\n        # Listing subdirectories\n        # Loop through the files in red folder  \n        # and combine, into a dictionary, the other bands\n        \n        self.files = [self.combine_files(f, green_dir, blue_dir, nir_dir, gt_dir) \n                      for f in red_dir.iterdir() if not f.is_dir()]\n        \n                \n        random.seed (seed)\n        self.files = random.sample (self.files, k= 10000)\n        \n    def combine_files(self, red_file: Path, green_dir, blue_dir, nir_dir, gt_dir):\n        \n        files = {'red': red_file, \n                 'green':green_dir/red_file.name.replace('red', 'green'),\n                 'blue': blue_dir/red_file.name.replace('red', 'blue'), \n                 'nir': nir_dir/red_file.name.replace('red', 'nir'),\n                 'gt': gt_dir/red_file.name.replace('red', 'gt')}\n\n        return files\n    \n    \n    \n    def OpenAsArray(self, idx, invert=False, include_nir=False):\n        \n        raw_rgb=np.stack([np.array(Image.open(self.files[idx]['red'])),\n                          np.array(Image.open(self.files[idx]['green'])),\n                          np.array(Image.open(self.files[idx]['blue']))], axis = 2)\n     \n     \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), axis = 2)\n            raw_rgb = np.concatenate([raw_rgb, nir], axis = 2) \n                          \n        if invert:\n            raw_rgb = raw_rgb.transpose((2, 0, 1))\n    \n    \n        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n    \n    \n    \n    \n    def OpenMask(self, idx, add_dims=False):\n        \n        raw_mask=np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n\n\n\n        \n    def __len__(self):\n        \n        return len(self.files)\n    \n    \n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.OpenAsArray(idx, invert=True, include_nir=True), dtype=torch.float32)\n        y = torch.tensor(self.OpenMask(idx, add_dims=False), dtype=torch.int64)\n        \n        return x, y\n    \n    \n    \n    def open_as_pil(self, idx):\n        \n        arr = 256 * self.OpenAsArray(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')  \n    \n    \n    \n    def __repr__(self):\n        \n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/95cloud-cloud-segmentation-on-satellite-images/95-cloud_training_only_additional_to38-cloud')\nred_dir   = base_path/'train_red_additional_to38cloud'\nblue_dir  = base_path/'train_blue_additional_to38cloud'\ngreen_dir = base_path/'train_green_additional_to38cloud'\nnir_dir   = base_path/'train_nir_additional_to38cloud'\ngt_dir    = base_path/'train_gt_additional_to38cloud' ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = CloudDataset(red_dir, blue_dir, green_dir, nir_dir, gt_dir)  \n# splitting the data into train, validation, and test datasets\n\ntrain_size = int(0.75 * len(data))\nvalid_size = int(0.15 * len(data))\ntest_size  = len(data) - train_size - valid_size\nremaining_size = len(data) - train_size \n\ntrain_dataset, remaining_dataset = torch.utils.data.random_split(data, [train_size, remaining_size])\nvalid_dataset, test_dataset      = torch.utils.data.random_split(remaining_dataset, [valid_size, test_size])\n\n\nprint('\\t\\t\\tDataset')\nprint(\"Train data: \\t\\t{}\".format(len(train_dataset)),\n      \"\\nValidation data: \\t{}\".format(len(valid_dataset)),\n     \"\\nTest data: \\t\\t{}\".format(len(test_dataset)))\n\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_loader  = DataLoader(test_dataset , batch_size=32, shuffle=False, num_workers=2)\n\nrgb_img, mask = next(iter(valid_loader))\n\nprint('\\n')\nprint('Raw RGB image shape on batch size = {}'.format(rgb_img.size()))\nprint('Cloud Mask shape on batch size    = {}'.format(mask.size()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y =data[100]\nx.shape, y. shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (10,9))\nax[0].imshow(data.OpenAsArray(100))\nax[1].imshow(data.OpenMask(100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model: A simple Unet**","metadata":{}},{"cell_type":"code","source":"class U_net(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(U_net, self).__init__()\n            \n        # downsampling part\n        self.DownConv1 = self.ContractBlock(in_channels, 32, 7, 3)\n        self.DownConv2 = self.ContractBlock(32, 64, 3, 1)\n        self.DownConv3 = self.ContractBlock(64, 128, 3, 1)\n            \n        # upsampling part\n        self.UpConv3 = self.ExpandBlock(128, 64, 3, 1)\n        self.UpConv2 = self.ExpandBlock(64*2, 32, 3, 1)\n        self.UpConv1 = self.ExpandBlock(32*2, out_channels, 3, 1)\n        \n    def __call__(self, x):\n         \n        DownConv1 = self.DownConv1(x)\n        DownConv2 = self.DownConv2(DownConv1) \n        DownConv3 = self.DownConv3(DownConv2)   \n        UpConv3   = self.UpConv3 (DownConv3)\n        UpConv2   = self.UpConv2 (torch.cat([UpConv3, DownConv2], 1))\n        UpConv1   = self.UpConv1 (torch.cat([UpConv2, DownConv1], 1))\n        \n        return UpConv1\n        \n        \n    def ContractBlock(self, in_channels, out_channels, kernel_size, padding):\n        \n        contract = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        \n            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n    \n        return contract\n\n\n\n    def ExpandBlock(self, in_channels, out_channels, kernel_size, padding):\n        \n        expand = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        \n            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        \n            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) )\n    \n        return expand","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\n\nclass Evaluation_Metrics(nn.Module):\n    def __init__(self):\n        super(Evaluation_Metrics, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        pred = torch.round(prediction.softmax(dim=1)[:, 1])\n\n        # true positives, false positives, true negatives, false negatives\n        TP = torch.sum(pred * gt)\n        FP = torch.sum(pred * (1-gt))\n        TN = torch.sum((1-pred) * (1-gt))\n        FN = torch.sum((1-pred) * gt)\n    \n    \n        # Dice_Score/F1_Score\n        Dice_Score = (2 * TP + smooth)/(2*TP + FP + FN  + smooth)\n    \n        # Jaccard Coefficient: Intersection over Union\n        IoU = (TP + smooth)/(TP + FP + FN + smooth)\n    \n        # Recall\n        Recall= (TP + smooth)/(TP + FN + smooth)\n    \n        # Precision\n        Precision = (TP + smooth)/(TP + FP + smooth)\n\n    \n        return {'Dice_Score/F1_Score':Dice_Score, 'IoU':IoU, 'Recall': Recall, 'Precision': Precision}\n\n\n# Dice Loss function\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self,prediction, gt, smooth=1):\n        \n        # Softmax to get probabilities beteen 0 and 1\n        # Transform the prediction tensor of shape (N, C, H, W) --> tensor of shape (N, H, W)\n        pred = prediction.softmax(dim=1)[:, 1]\n        \n        #flatten label and prediction tensors\n        pred = pred.contiguous().view(-1)\n        gt = gt.contiguous().view(-1).to(torch.float32)\n        \n        intersection = (pred * gt).sum()                            \n        dice_loss =(2.*intersection + smooth)/(pred.sum() + gt.sum() + smooth)  \n        \n        return -torch.log(dice_loss)\n    \n\n#Binary cross-entropy (BCE)-Dice loss function\nclass DiceBCELoss(nn.Module):\n    def __init__(self):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        # Softmax to get probabilities beteen 0 and 1\n        # Transform the prediction tensor of shape (N, C, H, W) --> tensor of shape (N, H, W)\n        pred = prediction.softmax(dim=1)[:, 1]\n        \n        #flatten label and prediction tensors\n        pred = pred.contiguous().view(-1)\n        gt = gt.contiguous().view(-1).to(torch.float32)\n        \n        intersection = (pred * gt).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)/(pred.sum() + gt.sum() + smooth)  \n        BCE = F.binary_cross_entropy(pred, gt, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n        \n        return Dice_BCE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if the network works, using one batch of the training set\n\nU_net_model = U_net(4, 2)\nrgb_img, mask = next(iter(train_loader))\noutput = U_net_model (rgb_img)\noutput.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use GPU if it is available\nmodel = U_net_model.to(device)\n\n# Set the evaluation metrics and the loss function\nEvaluation = Evaluation_Metrics()\nloss_fn    = DiceBCELoss()\nlogDice_loss = DiceLoss()\n\n# Set the optimizer \noptimizer = optim.Adam(model.parameters(), lr=0.00001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_DSC(train_DSC, valid_DSC):\n    fig = plt.figure(figsize=(10, 10))\n    plt.plot(train_DSC, '-bx')\n    plt.plot(valid_DSC, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Dice Coefficient vs. No. of epochs');\n    \ndef plot_losses(train_losses, valid_losses):\n    fig = plt.figure(figsize=(10, 10))\n    plt.plot(train_losses, '-bx')\n    plt.plot(valid_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Dice Loss vs. No. of epochs');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dl, valid_dl, loss_fn, optimizer, Evaluation, epochs, save_path):\n    \n    start = time.time()\n    min_valid_epoch_loss = np.inf\n    best_DSC = 0.0\n    train_losses, valid_losses = [], []\n    train_DSC, train_IoU, train_recall, train_precision = [], [], [], [] \n    valid_DSC, valid_IoU, valid_recall, valid_precision = [], [], [], [] \n\n    for e in range(epochs):\n        print('Epoch  {}/{}'.format(e, epochs-1))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to train mode\n                dataloader = train_dl\n            else:\n                model.eval()  # Set model to evaluate mode\n                dataloader = valid_dl\n\n            running_loss = 0.0\n            running_DSC  = 0.0\n            running_IoU  = 0.0\n            running_recall  = 0.0\n            running_precision  = 0.0\n\n\n            # iterate over data\n            for x, y in dataloader:\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device)\n                \n\n                # forward pass \n                if phase == 'train':\n                    # zero the gradients\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss    = loss_fn(outputs, y)\n                    # backward + optimize only if in training phase\n                    # the backward pass frees the graph memory, so there is no \n                    # need for torch.no_grad in this training pass\n                    loss.backward()\n                    optimizer.step()\n                    # scheduler.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss    = loss_fn(outputs, y)\n\n                # stats - whatever is the phase  \n                acc = Evaluation(outputs, y)\n                running_DSC        += acc['Dice_Score/F1_Score'].item()* dataloader.batch_size\n                running_IoU        += acc['IoU'].item()* dataloader.batch_size\n                running_recall     += acc['Recall'].item()* dataloader.batch_size\n                running_precision  += acc['Precision'].item()* dataloader.batch_size    \n                \n                running_loss += loss.item() * dataloader.batch_size\n                    \n            epoch_loss       = running_loss/ len(dataloader.dataset)\n            epoch_DSC        = running_DSC / len(dataloader.dataset)\n            epoch_IoU        = running_IoU / len(dataloader.dataset)\n            epoch_Recall     = running_recall / len(dataloader.dataset)\n            epoch_Precision  = running_precision / len(dataloader.dataset)\n            \n\n            print('{}\\nDice Loss: {:.3f}\\tDice Coefficient: {:.3f}\\tJaccard Coefficient: {:.3f}\\tPrecision: {:.3f}\\tRecall: {:.3f}'.format( phase, epoch_loss, epoch_DSC, epoch_IoU, epoch_Precision, epoch_Recall))\n            print()\n\n            train_losses.append(epoch_loss), train_DSC.append(epoch_DSC),train_IoU.append(epoch_IoU),train_recall.append(epoch_Recall),train_precision.append(epoch_Precision) if phase=='train' else valid_losses.append(epoch_loss), valid_DSC.append(epoch_DSC),valid_IoU.append(epoch_IoU),valid_recall.append(epoch_Recall),valid_precision.append(epoch_Precision)\n\n            \n             \n             # save model if validation loss has decreased\n            if phase == 'valid':\n                if epoch_loss <= min_valid_epoch_loss:\n                    print('Validation Dice loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n                        min_valid_epoch_loss, epoch_loss)) \n                    print('Best Validation Dice Score ({:.3f} --> {:.3f}).'.format(\n                        best_DSC, epoch_DSC))\n                    torch.save(model.state_dict(), save_path)\n                    min_valid_epoch_loss = epoch_loss\n                    best_DSC = epoch_DSC\n            \n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n    \n    \n    return train_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unet = './Benchmark_Unet_DiceBCE_lr5.pt'\ntrain_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC = train(model, train_loader, valid_loader, loss_fn, optimizer, Evaluation, epochs=50, save_path = Unet)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_DSC(train_DSC, valid_DSC)\nplt.savefig('./Dice_plot_Benchmark_Unet_lr5.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(train_losses, valid_losses)\nplt.savefig('./Losses_plot_Benchmark_Unet_lr5.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_to_img(xb, idx):\n    img = np.array(xb[idx,0:3])\n    return img.transpose((1,2,0))\n\ndef predb_to_mask(predb, idx):\n    p = torch.functional.F.softmax(predb[idx], 0)\n    return p.argmax(0).cpu()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/unet-logdice/Benchmark_Unet_DiceBCE_lr5.pt\"\n\nmodel = U_net(4, 2)\nmap_location=torch.device('cpu')\nmodel.load_state_dict(torch.load(PATH,map_location=torch.device('cpu')),strict=False)\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb, yb = next(iter(test_loader))\n\nwith torch.no_grad():\n    predb = model(xb.to(device))\n\npredb.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 32\nfig, ax = plt.subplots(bs,3, figsize=(15,bs*5))\nfor i in range(bs):\n    ax[i,0].imshow(batch_to_img(xb,i))\n    ax[i,1].imshow(yb[i])\n    ax[i,2].imshow(predb_to_mask(predb, i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss = 0.0\ntest_DSC  = 0.0\ntest_IoU  = 0.0\ntest_recall  = 0.0\ntest_precision  = 0.0\n\n\n# iterate over test data\nfor x, y in test_loader:\n    x = x.to(device, dtype=torch.float)\n    y = y.to(device)\n    \n    \n    with torch.no_grad():\n        model.eval()\n        outputs = model(x)\n        loss    = logDice_loss(outputs, y)\n                \n        # stats - whatever is the phase  \n        acc = Evaluation(outputs, y)\n        test_DSC        += acc['Dice_Score/F1_Score'].item()* test_loader.batch_size\n        test_IoU        += acc['IoU'].item()* test_loader.batch_size\n        test_recall     += acc['Recall'].item()* test_loader.batch_size\n        test_precision  += acc['Precision'].item()* test_loader.batch_size    \n        test_loss += loss.item() * test_loader.batch_size\n                    \nepoch_loss       = test_loss/ len(test_loader.dataset)\nepoch_DSC        = test_DSC / len(test_loader.dataset)\nepoch_IoU        = test_IoU / len(test_loader.dataset)\nepoch_Recall     = test_recall / len(test_loader.dataset)\nepoch_Precision  = test_precision / len(test_loader.dataset)\n            \n            \nprint('Dice Loss: {:.3f}\\tDice Coefficient: {:.3f}\\tJaccard Coefficient: {:.3f}\\tPrecision: {:.3f}\\tRecall: {:.3f}'.format(epoch_loss, epoch_DSC, epoch_IoU, epoch_Precision, epoch_Recall))\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}