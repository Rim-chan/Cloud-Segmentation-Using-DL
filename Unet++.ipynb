{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport torch\nimport time\nimport os\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nfrom skimage.transform import resize\nimport helper\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nfrom torchvision import datasets\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim, Tensor\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport random\nseed=42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-24T10:58:31.865554Z","iopub.execute_input":"2022-03-24T10:58:31.865866Z","iopub.status.idle":"2022-03-24T10:58:38.997891Z","shell.execute_reply.started":"2022-03-24T10:58:31.865797Z","shell.execute_reply":"2022-03-24T10:58:38.997000Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:58:38.999448Z","iopub.execute_input":"2022-03-24T10:58:38.999816Z","iopub.status.idle":"2022-03-24T10:58:39.052559Z","shell.execute_reply.started":"2022-03-24T10:58:38.999777Z","shell.execute_reply":"2022-03-24T10:58:39.051063Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class RGBCloudDataset (Dataset):\n    def __init__(self, red_dir, blue_dir, green_dir, gt_dir):\n        \n\n        # Listing subdirectories\n        # Loop through the files in red folder  \n        # and combine, into a dictionary, the other bands\n        \n        self.files = [self.combine_files(f, green_dir, blue_dir,gt_dir) \n                      for f in red_dir.iterdir() if not f.is_dir()]\n        \n        random.seed (seed)\n        self.files = random.sample (self.files, k= 4000)\n        \n    def combine_files(self, red_file: Path, green_dir, blue_dir,  gt_dir):\n        \n        files = {'red': red_file, \n                 'green':green_dir/red_file.name.replace('red', 'green'),\n                 'blue': blue_dir/red_file.name.replace('red', 'blue'), \n                 'gt': gt_dir/red_file.name.replace('red', 'gt')}\n\n        return files\n    \n    \n    \n    def OpenAsArray(self, idx, invert=False):\n        \n        raw_rgb=np.stack([np.array(Image.open(self.files[idx]['red'])),\n                          np.array(Image.open(self.files[idx]['green'])),\n                          np.array(Image.open(self.files[idx]['blue']))], axis = 2)\n     \n\n        if invert:\n            raw_rgb = raw_rgb.transpose((2, 0, 1))\n    \n    \n        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n    \n    \n    \n    \n    def OpenMask(self, idx, add_dims=False):\n        \n        raw_mask=np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n\n\n\n        \n    def __len__(self):\n        \n        return len(self.files)\n    \n    \n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.OpenAsArray(idx, invert=True), dtype=torch.float32)\n        y = torch.tensor(self.OpenMask(idx, add_dims=False), dtype=torch.int64)\n        \n        return x, y\n    \n    \n    \n    def open_as_pil(self, idx):\n        \n        arr = 256 * self.OpenAsArray(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')  \n    \n    \n    \n    def __repr__(self):\n        \n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:58:39.054854Z","iopub.execute_input":"2022-03-24T10:58:39.055504Z","iopub.status.idle":"2022-03-24T10:58:39.078388Z","shell.execute_reply.started":"2022-03-24T10:58:39.055458Z","shell.execute_reply":"2022-03-24T10:58:39.077396Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/95cloud-cloud-segmentation-on-satellite-images/95-cloud_training_only_additional_to38-cloud')\nred_dir   = base_path/'train_red_additional_to38cloud'\nblue_dir  = base_path/'train_blue_additional_to38cloud'\ngreen_dir = base_path/'train_green_additional_to38cloud'\nnir_dir   = base_path/'train_nir_additional_to38cloud'\ngt_dir    = base_path/'train_gt_additional_to38cloud' ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:58:39.080149Z","iopub.execute_input":"2022-03-24T10:58:39.080549Z","iopub.status.idle":"2022-03-24T10:58:39.089781Z","shell.execute_reply.started":"2022-03-24T10:58:39.080516Z","shell.execute_reply":"2022-03-24T10:58:39.088905Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Resize_data(object):\n    def __init__(self, size = 256):\n        self.size = size\n    def __call__(self, sample):\n        x, y = sample\n        return (resize(x, (x.shape[0], self.size, self.size), mode = \"constant\", \n                      preserve_range = True, anti_aliasing = False),\n                resize(y, (self.size, self.size), mode = \"constant\", \n                      preserve_range = True, anti_aliasing = False))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:58:39.091208Z","iopub.execute_input":"2022-03-24T10:58:39.091792Z","iopub.status.idle":"2022-03-24T10:58:39.100517Z","shell.execute_reply.started":"2022-03-24T10:58:39.091736Z","shell.execute_reply":"2022-03-24T10:58:39.099648Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transforms=transforms.Compose([transforms.Resize(256),\n                                    transforms.ToTensor()])\nRGBdata = RGBCloudDataset(red_dir, blue_dir, green_dir, gt_dir)\n\n# splitting the data into train, validation, and test datasets\n\ntrain_size = int(0.75 * len(RGBdata))\nvalid_size = int(0.15 * len(RGBdata))\ntest_size  = len(RGBdata) - train_size - valid_size\nremaining_size = len(RGBdata) - train_size \n\nRGBtrain_dataset, RGBremaining_dataset = torch.utils.data.random_split(RGBdata, [train_size, remaining_size])\nRGBvalid_dataset, RGBtest_dataset      = torch.utils.data.random_split(RGBremaining_dataset, [valid_size, test_size])\n\n\nprint('\\t\\t\\tDataset')\nprint(\"Train data: \\t\\t{}\".format(len(RGBtrain_dataset)),\n      \"\\nValidation data: \\t{}\".format(len(RGBvalid_dataset)),\n     \"\\nTest data: \\t\\t{}\".format(len(RGBtest_dataset)))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:58:39.102011Z","iopub.execute_input":"2022-03-24T10:58:39.102266Z","iopub.status.idle":"2022-03-24T10:59:07.812001Z","shell.execute_reply.started":"2022-03-24T10:58:39.102241Z","shell.execute_reply":"2022-03-24T10:59:07.811089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"RGBtrain_loader = DataLoader(RGBtrain_dataset, batch_size=5, shuffle=True, num_workers=2)\nRGBvalid_loader = DataLoader(RGBvalid_dataset, batch_size=5, shuffle=True, num_workers=2)\nRGBtest_loader  = DataLoader(RGBtest_dataset , batch_size=5, shuffle=True, num_workers=2)\n\nrgb_img, mask = next(iter(RGBtrain_loader))\n\nprint('\\n')\nprint('Raw RGB image shape on batch size = {}'.format(rgb_img.size()))\nprint('Cloud Mask shape on batch size    = {}'.format(mask.size()))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:59:07.813155Z","iopub.execute_input":"2022-03-24T10:59:07.813496Z","iopub.status.idle":"2022-03-24T10:59:08.309101Z","shell.execute_reply.started":"2022-03-24T10:59:07.813467Z","shell.execute_reply":"2022-03-24T10:59:08.308153Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"x, y =RGBdata[100]\nx.shape, y. shape","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:43:05.163234Z","iopub.execute_input":"2022-03-24T10:43:05.163756Z","iopub.status.idle":"2022-03-24T10:43:05.256015Z","shell.execute_reply.started":"2022-03-24T10:43:05.163720Z","shell.execute_reply":"2022-03-24T10:43:05.255172Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (10,9))\nax[0].imshow(RGBdata.OpenAsArray(100))\nax[1].imshow(RGBdata.OpenMask(100))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:43:07.314493Z","iopub.execute_input":"2022-03-24T10:43:07.315189Z","iopub.status.idle":"2022-03-24T10:43:07.768162Z","shell.execute_reply.started":"2022-03-24T10:43:07.315139Z","shell.execute_reply":"2022-03-24T10:43:07.767087Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## **Unet++**","metadata":{}},{"cell_type":"code","source":"class UnetPlusPlus_block_nested (nn.Module):\n    \n    def __init__(self, in_channels, mid_channels, out_channels):\n        super(UnetPlusPlus_block_nested, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n        self.bn1   = nn.BatchNorm2d(mid_channels)\n        self.relu  = nn.ReLU()\n        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n        self.bn2   = nn.BatchNorm2d(out_channels)\n    \n    def forward (self, x):\n        \n        x = self.conv1(x)\n        x = self.bn1 (x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2 (x)\n        x = self.relu(x)  \n        \n        return x\n\n\nclass UnetPlusPlus_nested(nn.Module):\n    \n    def __init__(self, in_channels=3, out_channels=2):\n        super(UnetPlusPlus_nested, self).__init__()\n        \n        n = 64\n        filters = [n, n * 2, n * 4, n * 8, n * 16]        \n        \n        self.pool     = nn.MaxPool2d (kernel_size=2, stride=2)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        \n        self.conv0_0 = UnetPlusPlus_block_nested (in_channels, filters[0], filters[0])\n        self.conv1_0 = UnetPlusPlus_block_nested (filters[0] , filters[1], filters[1])\n        self.conv2_0 = UnetPlusPlus_block_nested (filters[1] , filters[2], filters[2])\n        self.conv3_0 = UnetPlusPlus_block_nested (filters[2] , filters[3], filters[3])\n        self.conv4_0 = UnetPlusPlus_block_nested (filters[3] , filters[4], filters[4])        \n\n        self.conv0_1 = UnetPlusPlus_block_nested (filters[0] + filters[1], filters[0], filters[0])\n        self.conv1_1 = UnetPlusPlus_block_nested (filters[1] + filters[2], filters[1], filters[1])\n        self.conv2_1 = UnetPlusPlus_block_nested (filters[2] + filters[3], filters[2], filters[2])\n        self.conv3_1 = UnetPlusPlus_block_nested (filters[3] + filters[4], filters[3], filters[3])        \n        \n        self.conv0_2 = UnetPlusPlus_block_nested (filters[0]*2 + filters[1], filters[0], filters[0])\n        self.conv1_2 = UnetPlusPlus_block_nested (filters[1]*2 + filters[2], filters[1], filters[1])\n        self.conv2_2 = UnetPlusPlus_block_nested (filters[2]*2 + filters[3], filters[2], filters[2])\n        \n        self.conv0_3 = UnetPlusPlus_block_nested (filters[0]*3 + filters[1], filters[0], filters[0])\n        self.conv1_3 = UnetPlusPlus_block_nested (filters[1]*3 + filters[2], filters[1], filters[1])\n        \n        self.conv0_4 = UnetPlusPlus_block_nested (filters[0]*4 + filters[1], filters[0], filters[0])\n        \n        self.final   = nn.Conv2d(filters[0], out_channels, kernel_size=1)\n        \n        \n    def forward (self, x):\n        \n        x0_0 = self.conv0_0(x)\n        x1_0 = self.conv1_0(self.pool(x0_0))\n        x0_1 = self.conv0_1(torch.cat([x0_0, self.upsample(x1_0)], 1))\n        \n        x2_0 = self.conv2_0(self.pool(x1_0))\n        x1_1 = self.conv1_1(torch.cat([x1_0, self.upsample(x2_0)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.upsample(x1_1)], 1))\n        \n        x3_0 = self.conv3_0(self.pool(x2_0))\n        x2_1 = self.conv2_1(torch.cat([x2_0, self.upsample(x3_0)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.upsample(x2_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.upsample(x1_2)], 1))\n\n        x4_0 = self.conv4_0(self.pool(x3_0))\n        x3_1 = self.conv3_1(torch.cat([x3_0, self.upsample(x4_0)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.upsample(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.upsample(x2_2)], 1))\n        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.upsample(x1_3)], 1))\n        \n        output = self.final(x0_4)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:59:08.312329Z","iopub.execute_input":"2022-03-24T10:59:08.312624Z","iopub.status.idle":"2022-03-24T10:59:08.336702Z","shell.execute_reply.started":"2022-03-24T10:59:08.312594Z","shell.execute_reply":"2022-03-24T10:59:08.335648Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\n\nclass Evaluation_Metrics(nn.Module):\n    def __init__(self):\n        super(Evaluation_Metrics, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        pred = torch.round(prediction.softmax(dim=1)[:, 1])\n\n        # true positives, false positives, true negatives, false negatives\n        TP = torch.sum(pred * gt)\n        FP = torch.sum(pred * (1-gt))\n        TN = torch.sum((1-pred) * (1-gt))\n        FN = torch.sum((1-pred) * gt)\n    \n    \n        # Dice_Score/F1_Score\n        Dice_Score = (2 * TP + smooth)/(2*TP + FP + FN  + smooth)\n    \n        # Jaccard Coefficient: Intersection over Union\n        IoU = (TP + smooth)/(TP + FP + FN + smooth)\n    \n        # Recall\n        Recall= (TP + smooth)/(TP + FN + smooth)\n    \n        # Precision\n        Precision = (TP + smooth)/(TP + FP + smooth)\n\n    \n        return {'Dice_Score/F1_Score':Dice_Score, 'IoU':IoU, 'Recall': Recall, 'Precision': Precision}\n\n\n# Dice Loss function\nclass DiceBCELoss(nn.Module):\n    def __init__(self):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, prediction, gt, smooth=1):\n        \n        # Softmax to get probabilities beteen 0 and 1\n        # Transform the prediction tensor of shape (N, C, H, W) --> tensor of shape (N, H, W)\n        pred = prediction.softmax(dim=1)[:, 1]\n        \n        #flatten label and prediction tensors\n        pred = pred.contiguous().view(-1)\n        gt = gt.contiguous().view(-1).to(torch.float32)\n        \n        intersection = (pred * gt).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)/(pred.sum() + gt.sum() + smooth)  \n        BCE = F.binary_cross_entropy(pred, gt, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n        \n        return Dice_BCE\n    \n\n# Dice Loss function\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self,prediction, gt, smooth=1):\n        \n        # Softmax to get probabilities beteen 0 and 1\n        # Transform the prediction tensor of shape (N, C, H, W) --> tensor of shape (N, H, W)\n        pred = prediction.softmax(dim=1)[:, 1]\n        \n        #flatten label and prediction tensors\n        pred = pred.contiguous().view(-1)\n        gt = gt.contiguous().view(-1).to(torch.float32)\n        \n        intersection = (pred * gt).sum()                            \n        dice_loss =(2.*intersection + smooth)/(pred.sum() + gt.sum() + smooth)  \n        \n        return -torch.log(dice_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:59:08.338088Z","iopub.execute_input":"2022-03-24T10:59:08.338698Z","iopub.status.idle":"2022-03-24T10:59:08.354487Z","shell.execute_reply.started":"2022-03-24T10:59:08.338658Z","shell.execute_reply":"2022-03-24T10:59:08.353651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Use GPU if it is available\nmodel = UnetPlusPlus_nested(3,2).to(device)\n\n# Set the evaluation metrics and the loss function\nEvaluation = Evaluation_Metrics()\nloss_fn    = DiceBCELoss()\nlogDice_loss = DiceLoss()\n\n# Set the optimizer \noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:59:08.355662Z","iopub.execute_input":"2022-03-24T10:59:08.356197Z","iopub.status.idle":"2022-03-24T10:59:14.600271Z","shell.execute_reply.started":"2022-03-24T10:59:08.356158Z","shell.execute_reply":"2022-03-24T10:59:14.599445Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nsummary(model, (3, 384, 384))  ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:43:34.507907Z","iopub.execute_input":"2022-03-24T10:43:34.508300Z","iopub.status.idle":"2022-03-24T10:44:07.168571Z","shell.execute_reply.started":"2022-03-24T10:43:34.508269Z","shell.execute_reply":"2022-03-24T10:44:07.166184Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#checking if we have the correct dimensions for our (3,384,384) images\n#summary(Vgg16, (3, 384, 384))   \ntorch.cuda.empty_cache()\n# checking if the network works, using one batch of the training set\nrgb_img, mask = next(iter(RGBtrain_loader))\n\nrgb_img, mask = rgb_img.to(device), mask.to(device) \noutput = model (rgb_img)\noutput.shape, mask.shape ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:47:18.176904Z","iopub.execute_input":"2022-03-24T10:47:18.177384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.memory_summary(device=None, abbreviated=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_DSC(train_DSC, valid_DSC, metric):\n    fig = plt.figure(figsize=(10, 10))\n    plt.plot(train_DSC, '-bx')\n    plt.plot(valid_DSC, '-rx')\n    plt.xlabel('epoch')\n    # Metric = 'Accuracy' or 'Dice Coefficient'\n    plt.ylabel(metric)\n    plt.title(metric+' vs. No. of epochs'); \n    \n    \ndef plot_losses(train_losses, valid_losses, metric):\n    fig = plt.figure(figsize=(10, 10))\n    plt.plot(train_losses, '-bx')\n    plt.plot(valid_losses, '-rx')\n    plt.xlabel('epoch')\n    # Metric = 'Dice Loss' or '- Log Dice loss'\n    plt.ylabel(metric)\n    plt.legend(['Training', 'Validation'])\n    plt.title(metric+' vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:59:14.601533Z","iopub.execute_input":"2022-03-24T10:59:14.601856Z","iopub.status.idle":"2022-03-24T10:59:14.608981Z","shell.execute_reply.started":"2022-03-24T10:59:14.601823Z","shell.execute_reply":"2022-03-24T10:59:14.607318Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dl, valid_dl, loss_fn, optimizer, Evaluation, epochs, save_path):\n    \n    start = time.time()\n    min_valid_epoch_loss = np.inf\n    best_DSC = 0.0\n    train_losses, valid_losses = [], []\n    train_DSC, train_IoU, train_recall, train_precision = [], [], [], [] \n    valid_DSC, valid_IoU, valid_recall, valid_precision = [], [], [], [] \n\n    for e in range(epochs):\n        print('Epoch  {}/{}'.format(e, epochs-1))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to train mode\n                dataloader = train_dl\n            else:\n                model.eval()  # Set model to evaluate mode\n                dataloader = valid_dl\n\n            running_loss = 0.0\n            running_DSC  = 0.0\n            running_IoU  = 0.0\n            running_recall  = 0.0\n            running_precision  = 0.0\n\n\n            # iterate over data\n            for x, y in dataloader:\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device)\n                \n\n                # forward pass \n                if phase == 'train':\n                    # zero the gradients\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss    = loss_fn(outputs, y)\n                    # backward + optimize only if in training phase\n                    # the backward pass frees the graph memory, so there is no \n                    # need for torch.no_grad in this training pass\n                    loss.backward()\n                    optimizer.step()\n                    # scheduler.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss    = loss_fn(outputs, y)\n\n                # stats - whatever is the phase  \n                acc = Evaluation(outputs, y)\n                running_DSC        += acc['Dice_Score/F1_Score'].item()* dataloader.batch_size\n                running_IoU        += acc['IoU'].item()* dataloader.batch_size\n                running_recall     += acc['Recall'].item()* dataloader.batch_size\n                running_precision  += acc['Precision'].item()* dataloader.batch_size    \n                \n                running_loss += loss.item() * dataloader.batch_size\n                    \n            epoch_loss       = running_loss/ len(dataloader.dataset)\n            epoch_DSC        = running_DSC / len(dataloader.dataset)\n            epoch_IoU        = running_IoU / len(dataloader.dataset)\n            epoch_Recall     = running_recall / len(dataloader.dataset)\n            epoch_Precision  = running_precision / len(dataloader.dataset)\n            \n\n            print('{}\\nDice Loss: {:.3f}\\tDice Coefficient: {:.3f}\\tJaccard Coefficient: {:.3f}\\tPrecision: {:.3f}\\tRecall: {:.3f}'.format( phase, epoch_loss, epoch_DSC, epoch_IoU, epoch_Precision, epoch_Recall))\n            print()\n\n            train_losses.append(epoch_loss), train_DSC.append(epoch_DSC),train_IoU.append(epoch_IoU),train_recall.append(epoch_Recall),train_precision.append(epoch_Precision) if phase=='train' else valid_losses.append(epoch_loss), valid_DSC.append(epoch_DSC),valid_IoU.append(epoch_IoU),valid_recall.append(epoch_Recall),valid_precision.append(epoch_Precision)\n\n            \n             \n             # save model if validation loss has decreased\n            if phase == 'valid':\n                if epoch_loss <= min_valid_epoch_loss:\n                    print('Validation Dice loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n                        min_valid_epoch_loss, epoch_loss)) \n                    print('Best Validation Dice Score ({:.3f} --> {:.3f}).'.format(\n                        best_DSC, epoch_DSC))\n                    torch.save(model.state_dict(), save_path)\n                    min_valid_epoch_loss = epoch_loss\n                    best_DSC = epoch_DSC\n            \n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n    \n    \n    return train_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:21:38.193734Z","iopub.execute_input":"2021-05-23T16:21:38.194192Z","iopub.status.idle":"2021-05-23T16:21:38.214346Z","shell.execute_reply.started":"2021-05-23T16:21:38.194135Z","shell.execute_reply":"2021-05-23T16:21:38.213489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unetpp = './Unetpp_DiceBCE.pt'\ntrain_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC = train(model, RGBtrain_loader, RGBvalid_loader, loss_fn, optimizer, Evaluation, epochs=20, save_path = Unetpp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_DSC(train_DSC, valid_DSC, 'Dice Coefficient')\nplt.savefig('./Dice_plot_UnetPlusPlus.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(train_losses, valid_losses, 'Dice Loss')\nplt.savefig('./Losses_plot_UnetPlusPlus.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3 Layers Unet++**","metadata":{}},{"cell_type":"code","source":"class UnetPlusPlus_block_nested (nn.Module):\n    \n    def __init__(self, in_channels, mid_channels, out_channels):\n        super(UnetPlusPlus_block_nested, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n        self.bn1   = nn.BatchNorm2d(mid_channels)\n        self.relu  = nn.ReLU()\n        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n        self.bn2   = nn.BatchNorm2d(out_channels)\n    \n    def forward (self, x):\n        \n        x = self.conv1(x)\n        x = self.bn1 (x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2 (x)\n        x = self.relu(x)  \n        \n        return x\n\n\nclass UnetPlusPlus_nested(nn.Module):\n    \n    def __init__(self, in_channels=3, out_channels=2):\n        super(UnetPlusPlus_nested, self).__init__()\n        \n        n = 64\n        filters = [n, n * 2, n * 4, n * 8, n * 16]        \n        \n        self.pool     = nn.MaxPool2d (kernel_size=2, stride=2)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        \n        self.conv0_0 = UnetPlusPlus_block_nested (in_channels, filters[0], filters[0])\n        self.conv1_0 = UnetPlusPlus_block_nested (filters[0] , filters[1], filters[1])\n        self.conv2_0 = UnetPlusPlus_block_nested (filters[1] , filters[2], filters[2])\n        self.conv3_0 = UnetPlusPlus_block_nested (filters[2] , filters[3], filters[3])       \n\n        self.conv0_1 = UnetPlusPlus_block_nested (filters[0] + filters[1], filters[0], filters[0])\n        self.conv1_1 = UnetPlusPlus_block_nested (filters[1] + filters[2], filters[1], filters[1])\n        self.conv2_1 = UnetPlusPlus_block_nested (filters[2] + filters[3], filters[2], filters[2])       \n        \n        self.conv0_2 = UnetPlusPlus_block_nested (filters[0]*2 + filters[1], filters[0], filters[0])\n        self.conv1_2 = UnetPlusPlus_block_nested (filters[1]*2 + filters[2], filters[1], filters[1])\n        \n        self.conv0_3 = UnetPlusPlus_block_nested (filters[0]*3 + filters[1], filters[0], filters[0])\n        \n        self.final   = nn.Conv2d(filters[0], out_channels, kernel_size=1)\n        \n        \n    def forward (self, x):\n        \n        x0_0 = self.conv0_0(x)\n        x1_0 = self.conv1_0(self.pool(x0_0))\n        x0_1 = self.conv0_1(torch.cat([x0_0, self.upsample(x1_0)], 1))\n        \n        x2_0 = self.conv2_0(self.pool(x1_0))\n        x1_1 = self.conv1_1(torch.cat([x1_0, self.upsample(x2_0)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.upsample(x1_1)], 1))\n        \n        x3_0 = self.conv3_0(self.pool(x2_0))\n        x2_1 = self.conv2_1(torch.cat([x2_0, self.upsample(x3_0)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.upsample(x2_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.upsample(x1_2)], 1))\n        \n        output = self.final(x0_3)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:21:38.215877Z","iopub.execute_input":"2021-05-23T16:21:38.216354Z","iopub.status.idle":"2021-05-23T16:21:38.239087Z","shell.execute_reply.started":"2021-05-23T16:21:38.216312Z","shell.execute_reply":"2021-05-23T16:21:38.238142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use GPU if it is available\nmodel3 = UnetPlusPlus_nested(3,2).to(device)\n\n# Set the evaluation metrics and the loss function\nEvaluation = Evaluation_Metrics()\nloss_fn    = DiceBCELoss()\n\n# Set the optimizer \noptimizer = optim.Adam(model3.parameters(), lr=0.0001)\nUnetpp3 = './Unetpp2_DiceBCE.pt'\ntrain_losses, valid_losses, train_DSC, train_IoU, train_recall, train_precision,valid_DSC, valid_IoU, valid_recall, valid_precision, best_DSC = train(model3, RGBtrain_loader, RGBvalid_loader, loss_fn, optimizer, Evaluation, epochs=40, save_path = Unetpp3)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T21:13:42.195281Z","iopub.execute_input":"2021-05-23T21:13:42.195606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_DSC(train_DSC, valid_DSC, 'Dice Coefficient')   \nplt.savefig('./Dice_plot_UnetPlusPlus3.png')   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(train_losses, valid_losses, 'Dice Loss')\nplt.savefig('./Losses_plot_UnetPlusPlus3.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}